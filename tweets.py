# -*- coding: utf-8 -*-
"""tweets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kNTWSsMEdZ0n6HOuV9GpgEvFFeC98qeO
"""

!pip install ntscraper
!pip install transformers
!pip install scipy

import pandas as pd
from ntscraper import Nitter
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
import matplotlib.pyplot as plt
import plotly.express as px
import pytz
from datetime import datetime

"""## Modify to serach based on username, hashtags, or keywords. Change mode variable as well.

Note: this step may take a few minutes as it collects data
"""

scraper = Nitter(log_level=1, skip_instance_check=False)
twitter_username = "POTUS"

tweets = scraper.get_tweets(twitter_username, mode = 'user', since = '2023-12-01', until = '2023-12-31')

"""## preprocess text from each tweet to fit models needs"""

temp = []
timestamps = []
for tweet in tweets['tweets']: #go through every tweet
  timestamps.append(tweet['date'])
  tweet_words = []
  for word in tweet['text'].split(' '): # go through every word of every tweet
    if word.startswith('@') and len(word) > 1:
        word = '@user'

    elif word.startswith('http'):
        word = "http"

    tweet_words.append((word))

  temp.append((tweet_words))

final_tweets = []
for tweet in temp:
  tweet_proc = " ".join(tweet)
  final_tweets.append(tweet_proc)

final_tweets.reverse()
timestamps.reverse()

print(final_tweets)
print(timestamps)

roberta = "cardiffnlp/twitter-roberta-base-sentiment"

model = AutoModelForSequenceClassification.from_pretrained(roberta)
tokenizer = AutoTokenizer.from_pretrained(roberta)

labels = ['Negative', 'Neutral', 'Positive']

"""# Calculate the scores for each tweet"""

tweets_data = []
i = 0
for tweet in final_tweets:
  timestamp = timestamps[i]

  encoded_tweet = tokenizer(tweet, return_tensors='pt')
  output = model(**encoded_tweet)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)

  tweet_data = {
        "timestamp": timestamp,
        "tweet": tweet,
        "negative": scores[0],
        "neutral": scores[1],
        "positive": scores[2]
  }

  tweets_data.append(tweet_data)
  i+=1

df = pd.DataFrame(tweets_data)

df['timestamp'] = pd.to_datetime(df['timestamp'], format='%b %d, %Y Â· %I:%M %p %Z')
eastern = pytz.timezone('US/Eastern')
df['timestamp'] = df['timestamp'].dt.tz_convert(eastern)
df.set_index('timestamp', inplace=True)

max_length = 100 #tweets can be up to 280 characters
window_size = 10
df_smoothed = df[['negative', 'neutral', 'positive']].rolling(window=window_size).mean()
df_smoothed['tweet'] = df['tweet'].apply(lambda x: (x[:max_length] + '...') if len(x) > max_length else x)

fig = px.line(df_smoothed, x=df_smoothed.index, y='positive', title='Tweet Sentiment Scores Over Time',
              labels={'x': 'Timestamp', 'positive': 'Sentiment Score'},
              hover_data={'tweet': True}, markers=True)

# If you want to plot other sentiments, you can add them as well
# fig.add_scatter(x=df_smoothed.index, y=df_smoothed['negative'], mode='lines', name='Negative')
# fig.add_scatter(x=df_smoothed.index, y=df_smoothed['neutral'], mode='lines', name='Neutral')

fig.update_xaxes(title_text='Timestamp')
fig.update_yaxes(title_text='Sentiment Score')
fig.update_layout(legend_title_text='Sentiment Type')
fig.show()